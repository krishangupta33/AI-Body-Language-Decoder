{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishan/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils  # Drawing utilities\n",
    "mp_holistic = mp.solutions.holistic  # Holistic model\n",
    "mp_drawing_styles = mp.solutions.drawing_styles  # Drawing styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make some detections   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1704940024.019140       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)  # 0 for webcam\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # To improve performance by making image writeable to false as we are not going to edit the image \n",
    "\n",
    "        # Make detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "\n",
    "        # Drawing face landmarks on the screen\n",
    "        if results.face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.face_landmarks, \n",
    "                mp_holistic.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None, \n",
    "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "\n",
    "        # Left Hand\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.left_hand_landmarks, \n",
    "                mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style())\n",
    "            \n",
    "#         used this line of code to change the colour of connections in the right hand\n",
    "#         mp_drawing.DrawingSpec(colour=(0,0,255),thickness=2,circle_radius=2)\n",
    "\n",
    "        # Right Hand\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.right_hand_landmarks, \n",
    "                mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2))\n",
    "\n",
    "        # Pose Detection\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, \n",
    "                mp_holistic.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "        cv2.imshow('Raw webcam feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Landmarks & Export to CSV\n",
    "<img src=\"https://i.imgur.com/8bForKY.png\">\n",
    "<img src=\"https://i.imgur.com/AzKNp7A.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5873932838439941"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample landmark coordinates\n",
    "results.face_landmarks.landmark[0].y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cords = 0\n",
    "\n",
    "if results.face_landmarks:\n",
    "    num_cords += len(results.face_landmarks.landmark)\n",
    "if results.pose_landmarks:\n",
    "    num_cords += len(results.pose_landmarks.landmark)\n",
    "if results.left_hand_landmarks:\n",
    "    num_cords += len(results.left_hand_landmarks.landmark)\n",
    "if results.right_hand_landmarks:\n",
    "    num_cords += len(results.right_hand_landmarks.landmark)\n",
    "num_cords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_cords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'x1', 'y1', 'z1', 'v1', 'x2', 'y2', 'z2', 'v2', 'x3']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we have class column and 501 columns for x,y,z and v coordinates\n",
    "landmarks[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"Five\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1704940322.467928       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Pro\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)  # 0 for webcam\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # To improve performance by making image writeable to false as we are not going to edit the image \n",
    "\n",
    "        # Make detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "\n",
    "        # Drawing face landmarks on the screen\n",
    "        if results.face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.face_landmarks, \n",
    "                mp_holistic.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None, \n",
    "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "\n",
    "        # Left Hand\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.left_hand_landmarks, \n",
    "                mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style())\n",
    "            \n",
    "#         used this line of code to change the colour of connections in the right hand\n",
    "#         mp_drawing.DrawingSpec(colour=(0,0,255),thickness=2,circle_radius=2)\n",
    "\n",
    "        # Right Hand\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.right_hand_landmarks, \n",
    "                mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2))\n",
    "\n",
    "        # Pose Detection\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, \n",
    "                mp_holistic.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "            \n",
    "        # Export coordinates\n",
    "        try:\n",
    "\n",
    "            #extracting pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "            #extracting face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "            #concatenating both face and pose landmarks\n",
    "            row = pose_row+face_row\n",
    "            #adding class name to the row\n",
    "            row.insert(0, class_name)\n",
    "\n",
    "            with open('coords.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cv2.imshow('Raw webcam feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Custom Model Using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Read in collected data and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>0.5199763774871826</th>\n",
       "      <th>0.803003191947937</th>\n",
       "      <th>-1.0043673515319824</th>\n",
       "      <th>0.9976217150688171</th>\n",
       "      <th>0.5543729066848755</th>\n",
       "      <th>0.7062968015670776</th>\n",
       "      <th>-1.013872742652893</th>\n",
       "      <th>0.9942453503608704</th>\n",
       "      <th>0.5754266977310181</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.03909732773900032</th>\n",
       "      <th>0.0.465</th>\n",
       "      <th>0.6112842559814453</th>\n",
       "      <th>0.6971602439880371</th>\n",
       "      <th>-0.026634424924850464</th>\n",
       "      <th>0.0.466</th>\n",
       "      <th>0.6168917417526245</th>\n",
       "      <th>0.6858875751495361</th>\n",
       "      <th>-0.027495795860886574</th>\n",
       "      <th>0.0.467</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Looking Down</td>\n",
       "      <td>0.535347</td>\n",
       "      <td>0.812029</td>\n",
       "      <td>-1.805548</td>\n",
       "      <td>0.997771</td>\n",
       "      <td>0.566254</td>\n",
       "      <td>0.711728</td>\n",
       "      <td>-1.815560</td>\n",
       "      <td>0.994722</td>\n",
       "      <td>0.585122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.613394</td>\n",
       "      <td>0.694047</td>\n",
       "      <td>-0.025039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618835</td>\n",
       "      <td>0.684762</td>\n",
       "      <td>-0.026042</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Looking Down</td>\n",
       "      <td>0.541345</td>\n",
       "      <td>0.815550</td>\n",
       "      <td>-1.876920</td>\n",
       "      <td>0.997903</td>\n",
       "      <td>0.571658</td>\n",
       "      <td>0.713589</td>\n",
       "      <td>-1.885020</td>\n",
       "      <td>0.995150</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.613227</td>\n",
       "      <td>0.695193</td>\n",
       "      <td>-0.023941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618444</td>\n",
       "      <td>0.686624</td>\n",
       "      <td>-0.024854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Looking Down</td>\n",
       "      <td>0.544462</td>\n",
       "      <td>0.817506</td>\n",
       "      <td>-1.848631</td>\n",
       "      <td>0.998019</td>\n",
       "      <td>0.574586</td>\n",
       "      <td>0.714434</td>\n",
       "      <td>-1.859255</td>\n",
       "      <td>0.995533</td>\n",
       "      <td>0.592701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612991</td>\n",
       "      <td>0.695920</td>\n",
       "      <td>-0.024354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618241</td>\n",
       "      <td>0.687358</td>\n",
       "      <td>-0.025285</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Looking Down</td>\n",
       "      <td>0.546885</td>\n",
       "      <td>0.818934</td>\n",
       "      <td>-1.938705</td>\n",
       "      <td>0.998111</td>\n",
       "      <td>0.577210</td>\n",
       "      <td>0.714866</td>\n",
       "      <td>-1.945508</td>\n",
       "      <td>0.995872</td>\n",
       "      <td>0.595267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612517</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>-0.023382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617745</td>\n",
       "      <td>0.687368</td>\n",
       "      <td>-0.024279</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking Down</td>\n",
       "      <td>0.548011</td>\n",
       "      <td>0.818996</td>\n",
       "      <td>-1.910009</td>\n",
       "      <td>0.998214</td>\n",
       "      <td>0.578623</td>\n",
       "      <td>0.714860</td>\n",
       "      <td>-1.911336</td>\n",
       "      <td>0.996187</td>\n",
       "      <td>0.596813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612838</td>\n",
       "      <td>0.696454</td>\n",
       "      <td>-0.022929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618081</td>\n",
       "      <td>0.688134</td>\n",
       "      <td>-0.023800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>Five</td>\n",
       "      <td>0.487322</td>\n",
       "      <td>0.548606</td>\n",
       "      <td>-0.619436</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.511866</td>\n",
       "      <td>0.482971</td>\n",
       "      <td>-0.560085</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.524985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538466</td>\n",
       "      <td>0.489367</td>\n",
       "      <td>0.021326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542884</td>\n",
       "      <td>0.483639</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>Five</td>\n",
       "      <td>0.487333</td>\n",
       "      <td>0.548015</td>\n",
       "      <td>-0.618375</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.511831</td>\n",
       "      <td>0.482319</td>\n",
       "      <td>-0.559165</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.524953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539079</td>\n",
       "      <td>0.489424</td>\n",
       "      <td>0.021623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543483</td>\n",
       "      <td>0.483628</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>Five</td>\n",
       "      <td>0.487319</td>\n",
       "      <td>0.547546</td>\n",
       "      <td>-0.616995</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.511780</td>\n",
       "      <td>0.481735</td>\n",
       "      <td>-0.558159</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.524896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539096</td>\n",
       "      <td>0.489115</td>\n",
       "      <td>0.021723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543516</td>\n",
       "      <td>0.483289</td>\n",
       "      <td>0.022496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Five</td>\n",
       "      <td>0.487021</td>\n",
       "      <td>0.547299</td>\n",
       "      <td>-0.606167</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.511529</td>\n",
       "      <td>0.481414</td>\n",
       "      <td>-0.548308</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.524663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539375</td>\n",
       "      <td>0.489107</td>\n",
       "      <td>0.021734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543800</td>\n",
       "      <td>0.483222</td>\n",
       "      <td>0.022515</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>Five</td>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.547143</td>\n",
       "      <td>-0.589901</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.511422</td>\n",
       "      <td>0.481168</td>\n",
       "      <td>-0.534169</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.524583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539757</td>\n",
       "      <td>0.488870</td>\n",
       "      <td>0.021791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544151</td>\n",
       "      <td>0.483063</td>\n",
       "      <td>0.022567</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class  0.5199763774871826  0.803003191947937  -1.0043673515319824  \\\n",
       "0    Looking Down            0.535347           0.812029            -1.805548   \n",
       "1    Looking Down            0.541345           0.815550            -1.876920   \n",
       "2    Looking Down            0.544462           0.817506            -1.848631   \n",
       "3    Looking Down            0.546885           0.818934            -1.938705   \n",
       "4    Looking Down            0.548011           0.818996            -1.910009   \n",
       "..            ...                 ...                ...                  ...   \n",
       "780          Five            0.487322           0.548606            -0.619436   \n",
       "781          Five            0.487333           0.548015            -0.618375   \n",
       "782          Five            0.487319           0.547546            -0.616995   \n",
       "783          Five            0.487021           0.547299            -0.606167   \n",
       "784          Five            0.486933           0.547143            -0.589901   \n",
       "\n",
       "     0.9976217150688171  0.5543729066848755  0.7062968015670776  \\\n",
       "0              0.997771            0.566254            0.711728   \n",
       "1              0.997903            0.571658            0.713589   \n",
       "2              0.998019            0.574586            0.714434   \n",
       "3              0.998111            0.577210            0.714866   \n",
       "4              0.998214            0.578623            0.714860   \n",
       "..                  ...                 ...                 ...   \n",
       "780            0.999999            0.511866            0.482971   \n",
       "781            0.999998            0.511831            0.482319   \n",
       "782            0.999998            0.511780            0.481735   \n",
       "783            0.999998            0.511529            0.481414   \n",
       "784            0.999998            0.511422            0.481168   \n",
       "\n",
       "     -1.013872742652893  0.9942453503608704  0.5754266977310181  ...  \\\n",
       "0             -1.815560            0.994722            0.585122  ...   \n",
       "1             -1.885020            0.995150            0.590000  ...   \n",
       "2             -1.859255            0.995533            0.592701  ...   \n",
       "3             -1.945508            0.995872            0.595267  ...   \n",
       "4             -1.911336            0.996187            0.596813  ...   \n",
       "..                  ...                 ...                 ...  ...   \n",
       "780           -0.560085            0.999995            0.524985  ...   \n",
       "781           -0.559165            0.999995            0.524953  ...   \n",
       "782           -0.558159            0.999994            0.524896  ...   \n",
       "783           -0.548308            0.999994            0.524663  ...   \n",
       "784           -0.534169            0.999994            0.524583  ...   \n",
       "\n",
       "     -0.03909732773900032  0.0.465  0.6112842559814453  0.6971602439880371  \\\n",
       "0               -0.037896      0.0            0.613394            0.694047   \n",
       "1               -0.037391      0.0            0.613227            0.695193   \n",
       "2               -0.037814      0.0            0.612991            0.695920   \n",
       "3               -0.037221      0.0            0.612517            0.695590   \n",
       "4               -0.036822      0.0            0.612838            0.696454   \n",
       "..                    ...      ...                 ...                 ...   \n",
       "780              0.003682      0.0            0.538466            0.489367   \n",
       "781              0.003720      0.0            0.539079            0.489424   \n",
       "782              0.003940      0.0            0.539096            0.489115   \n",
       "783              0.003835      0.0            0.539375            0.489107   \n",
       "784              0.003940      0.0            0.539757            0.488870   \n",
       "\n",
       "     -0.026634424924850464  0.0.466  0.6168917417526245  0.6858875751495361  \\\n",
       "0                -0.025039      0.0            0.618835            0.684762   \n",
       "1                -0.023941      0.0            0.618444            0.686624   \n",
       "2                -0.024354      0.0            0.618241            0.687358   \n",
       "3                -0.023382      0.0            0.617745            0.687368   \n",
       "4                -0.022929      0.0            0.618081            0.688134   \n",
       "..                     ...      ...                 ...                 ...   \n",
       "780               0.021326      0.0            0.542884            0.483639   \n",
       "781               0.021623      0.0            0.543483            0.483628   \n",
       "782               0.021723      0.0            0.543516            0.483289   \n",
       "783               0.021734      0.0            0.543800            0.483222   \n",
       "784               0.021791      0.0            0.544151            0.483063   \n",
       "\n",
       "     -0.027495795860886574  0.0.467  \n",
       "0                -0.026042      0.0  \n",
       "1                -0.024854      0.0  \n",
       "2                -0.025285      0.0  \n",
       "3                -0.024279      0.0  \n",
       "4                -0.023800      0.0  \n",
       "..                     ...      ...  \n",
       "780               0.022066      0.0  \n",
       "781               0.022392      0.0  \n",
       "782               0.022496      0.0  \n",
       "783               0.022515      0.0  \n",
       "784               0.022567      0.0  \n",
       "\n",
       "[785 rows x 2005 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridgeclassifier&#x27;, RidgeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;ridgeclassifier&#x27;, RidgeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('ridgeclassifier', RidgeClassifier())])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipelines.values())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishan/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Smiling'], dtype=object)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['lr'].predict(X_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Evaluate and Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0\n",
      "rc 1.0\n",
      "rf 1.0\n",
      "gb 1.0\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # 0 for webcam\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False # To improve performance by making image writeable to false as we are not going to edit the image \n",
    "\n",
    "        # Make detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "\n",
    "        # Drawing face landmarks on the screen\n",
    "        if results.face_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.face_landmarks, \n",
    "                mp_holistic.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None, \n",
    "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "\n",
    "        # Left Hand\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.left_hand_landmarks, \n",
    "                mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style())\n",
    "            \n",
    "#         used this line of code to change the colour of connections in the right hand\n",
    "#         mp_drawing.DrawingSpec(colour=(0,0,255),thickness=2,circle_radius=2)\n",
    "\n",
    "        # Right Hand\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.right_hand_landmarks, \n",
    "                mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2))\n",
    "\n",
    "        # Pose Detection\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, \n",
    "                mp_holistic.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "            \n",
    "        # Export coordinates\n",
    "        try:\n",
    "\n",
    "            #extracting pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "            #extracting face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "            #concatenating both face and pose landmarks\n",
    "            row = pose_row+face_row\n",
    "\n",
    "            # #adding class name to the row\n",
    "            # row.insert(0, class_name)\n",
    "\n",
    "            # with open('coords.csv', mode='a', newline='') as f:\n",
    "            #     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            #     csv_writer.writerow(row)\n",
    "\n",
    "            #make predictions\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            # print(body_language_class, body_language_prob)\n",
    "\n",
    "            #grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [1920,1080]).astype(int))\n",
    "            \n",
    "            cv2.rectangle(image, (coords[0], coords[1]+10), (coords[0]+len(body_language_class)*30, coords[1]-30), (245, 117, 16), -1)\n",
    "\n",
    "            cv2.putText(image, body_language_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "\n",
    "            #get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1) #top corner, bottom corner, colour, thickness\n",
    "\n",
    "            #display class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            #display probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cv2.imshow('Raw webcam feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
